# ТЗ: Система модерации клиентских обращений (MVP за 2 дня)

**Цель:** Создать конвейер обработки событий: `Kafka -> Service-1 -> (REST) -> Service-2 (Redis) -> Kafka`.

## 1. Схема данных (Контракты)
Чтобы не тратить время на выдумывание полей, используйте эти:

*   **Событие в Topic-1 (JSON):**
    ```json
    {
      "eventId": "uuid-123",
      "clientId": "client-777",
      "category": "billing", 
      "text": "Не прошел платеж",
      "timestamp": "2023-10-27T14:00:00Z"
    }
    ```
*   **Ответ Service-2 (JSON):**
    ```json
    {
      "clientId": "client-777",
      "hasActiveRequests": false,
      "isVIP": true
    }
    ```

---

## 2. Функциональные требования по шагам

### Шаг 1: Service-2 (Обогатитель данных) — Сделать за 3 часа
Простой REST-сервис, который работает с Redis.
*   **Эндпоинт:** `GET /info/{clientId}`.
*   **Логика:** Берет данные из Redis по ключу `clientId`.
*   **Важно:** Если в Redis пусто, сервис возвращает `404` или `200` с дефолтными значениями (например, `hasActiveRequests: false`). Service-1 должен это адекватно принять.

### Шаг 2: Service-1 (Модератор) — Основная работа
Слушает **Topic-1**, применяет фильтры и пишет в **Topic-2**.

**Логика фильтрации (бизнес-правила):**
1.  **Проверка на дубли (Идемпотентность):** Сохраняем `eventId` в Redis (с TTL 24 часа). Если пришло событие с уже существующим `eventId` — игнорируем.
2.  **Проверка на активные обращения:** Если `Service-2` ответил, что `hasActiveRequests: true` — стоп.
3.  **Рабочее время:** Если `category == "tech_support"` и время в `timestamp` вне диапазона 09:00–18:00 (МСК) — стоп. (Для других категорий — пропускаем всегда).

### Шаг 3: Инфраструктура
Используйте `docker-compose` с готовыми образами Kafka (например, `bitnami/kafka`) и Redis. Не тратьте время на установку на хост.

---

## 3. Технические требования (Как пройти проверку)

*   **Retry:** Если Service-2 недоступен, Service-1 должен сделать 3 попытки вызова (используйте библиотеку типа `tenacity` для Python или `resilience4j` для Java).
*   **Чистота:** Код в разных папках (`/service-1`, `/service-2`), один `docker-compose.yml` в корне.
*   **Логи:** Каждый этап должен логироваться ("Получено событие", "Дубликат пропущен", "Отправлено в Topic-2").

---

## План "Как успеть за 2 дня"

### День 1: Инфраструктура и Скелет
*   **0-2 час:** Настройка `docker-compose` (Kafka, Redis). Проверка, что всё крутится.
*   **2-5 час:** Написание **Service-2**. Наполнение Redis тестовыми данными (через скрипт или консоль).
*   **5-8 час:** Скелет **Service-1**: чтение из Kafka и логирование входящих сообщений.

### День 2: Логика и Тесты
*   **0-3 час:** Реализация вызова Service-2 из Service-1 и механизма Retry.
*   **3-6 час:** Реализация трех бизнес-правил (дубли, активные заявки, время).
*   **6-8 час:** Запись в Topic-2 и финальное тестирование (прогнать 5-10 разных сценариев).

---

### Подсказка по реализации правила "Рабочее время"
Чтобы не мучиться с часовыми поясами, просто возьмите час из `timestamp`:
```python
# Пример на Python
dt = datetime.fromisoformat(event['timestamp'])
if event['category'] == 'tech_support' and not (9 <= dt.hour < 18):
    return "Ignore: Non-working hours"
```

### Что НЕ нужно делать (чтобы сэкономить время):
1.  Не делайте сложную БД. Redis достаточно.
2.  Не делайте авторизацию.
3.  Не пишите 100% покрытие тестами — хватит 2-3 интеграционных сценариев.
4.  Не делайте сложный UI — только логи в консоли.